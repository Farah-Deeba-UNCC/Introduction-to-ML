{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Farah-Deeba-UNCC/Introduction-to-ML/blob/main/LinearRegression.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "tKZJhD4KbjKq"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Problem statement\n",
        "Suppose you are the CEO of a restaurant franchise and are considering different cities for opening a new outlet. The chain already has trucks in various cities and you have data for profits and populations from the cities. You would like to use this data to help you select which city to expand next.\n",
        "\n",
        "## Load data\n",
        " The first column is the population of a city and the second column is the profit of a food truck in that city. A negative value for profit indicates a loss. The dataset is loaded from the data file into the variables x and y:"
      ],
      "metadata": {
        "id": "YryJkRp_-1IZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "df =pd.read_csv('https://raw.githubusercontent.com/satishgunjal/datasets/master/univariate_profits_and_populations_from_the_cities.csv')\n",
        "df.head() # To get first n rows from the dataset default value of n is 5"
      ],
      "metadata": {
        "id": "kFeqxGMobnHr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X = df.loc[:,'population']\n",
        "Y = df.loc[:,'profit']"
      ],
      "metadata": {
        "id": "6odEn2lB_mBd"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Plot data\n",
        "Before starting on any task, it is often useful to understand the data by visualizing it. For this dataset, we can use a scatter plot to visualize the data, since it has only two variables (profit and population) to plot (a simple linear regression problem) .\n",
        "\n",
        "Note that many problems in real life are multi-dimensional (multiple linear regression problem) and canâ€™t be plotted on a 2-d plot.\n",
        "\n",
        "Now let's create a scatter plot of the data:"
      ],
      "metadata": {
        "id": "5Q-9OJyRAKXh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plt.scatter(X,Y)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "XK3uyKb7AETe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.scatter(X,Y, color='red',marker= '+')\n",
        "plt.grid()\n",
        "plt.xlabel('Population of City in 10,000s')\n",
        "plt.ylabel('Profit in $10,000s')\n",
        "plt.title('Scatter plot of training data')"
      ],
      "metadata": {
        "id": "OzzrqPKaBORa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "#Lets create a matrix with single column of ones\n",
        "X_0 = np.ones((m, 1))\n",
        "X_0[:5]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ffq4iq7TcB8F",
        "outputId": "9aa92e39-d4a8-4cee-a575-0c8267d406c0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[1.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [1.]])"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Using reshape function convert X 1D array to 2D array of dimension 97x1\n",
        "X_1 = X.reshape(m, 1)\n",
        "X_1[:10]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z3vngL_YcC1G",
        "outputId": "32e88575-eefa-4320-83a4-4e8c7ea12ca3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[6.1101],\n",
              "       [5.5277],\n",
              "       [8.5186],\n",
              "       [7.0032],\n",
              "       [5.8598],\n",
              "       [8.3829],\n",
              "       [7.4764],\n",
              "       [8.5781],\n",
              "       [6.4862],\n",
              "       [5.0546]])"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Lets use hstack() function from numpy to stack X_0 and X_1 horizontally (i.e. column\n",
        "# This will be our final X matrix (feature matrix)\n",
        "X = np.hstack((X_0, X_1))\n",
        "X[:5]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OBts7NcncIiG",
        "outputId": "30220f2d-07b0-4c6e-a4c1-ae559bcc1a6d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[1.    , 6.1101],\n",
              "       [1.    , 5.5277],\n",
              "       [1.    , 8.5186],\n",
              "       [1.    , 7.0032],\n",
              "       [1.    , 5.8598]])"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "theta = np.zeros(2)\n",
        "theta"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VRuJ27IscLZ2",
        "outputId": "65f3127e-4d47-4248-fea2-2d85a85d574d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0., 0.])"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def compute_cost(X, y, theta):\n",
        "  \"\"\"\n",
        "  Compute cost for linear regression.\n",
        "\n",
        "  Input Parameters\n",
        "  ----------------\n",
        "  X : 2D array where each row represent the training example and each column represent\n",
        "      m= number of training examples\n",
        "      n= number of features (including X_0 column of ones)\n",
        "  y : 1D array of labels/target value for each traing example. dimension(1 x m)\n",
        "\n",
        "  theta : 1D array of fitting parameters or weights. Dimension (1 x n)\n",
        "\n",
        "  Output Parameters\n",
        "  -----------------\n",
        "  J : Scalar value.\n",
        "  \"\"\"\n",
        "  predictions = X.dot(theta)\n",
        "  errors = np.subtract(predictions, y)\n",
        "  sqrErrors = np.square(errors)\n",
        "  J = 1 / (2 * m) * np.sum(sqrErrors)\n",
        "\n",
        "  return J"
      ],
      "metadata": {
        "id": "cd8ES87QcPUB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Lets compute the cost for theta values\n",
        "cost = compute_cost(X, y, theta)\n",
        "print('The cost for given values of theta_0 and theta_1 =', cost)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Cfgq5KYscVUY",
        "outputId": "e5b96bf1-9b03-4a40-cb11-a12df6a8b83a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The cost for given values of theta_0 and theta_1 = 32.072733877455676\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def gradient_descent(X, y, theta, alpha, iterations):\n",
        "  \"\"\"\n",
        "  Compute cost for linear regression.\n",
        "\n",
        "  Input Parameters\n",
        "  ----------------\n",
        "  X : 2D array where each row represent the training example and each column represent\n",
        "      m= number of training examples\n",
        "      n= number of features (including X_0 column of ones)\n",
        "  y : 1D array of labels/target value for each traing example. dimension(m x 1)\n",
        "  theta : 1D array of fitting parameters or weights. Dimension (1 x n)\n",
        "  alpha : Learning rate. Scalar value\n",
        "  iterations: No of iterations. Scalar value.\n",
        "\n",
        "  Output Parameters\n",
        "  -----------------\n",
        "  theta : Final Value. 1D array of fitting parameters or weights. Dimension (1 x n)\n",
        "  cost_history: Conatins value of cost for each iteration. 1D array. Dimansion(m x 1)  \"\"\"\n",
        "  cost_history = np.zeros(iterations)\n",
        "\n",
        "  for i in range(iterations):\n",
        "    predictions = X.dot(theta)\n",
        "    errors = np.subtract(predictions, y)\n",
        "    sum_delta = (alpha / m) * X.transpose().dot(errors);\n",
        "    theta = theta - sum_delta;\n",
        "    cost_history[i] = compute_cost(X, y, theta)\n",
        "\n",
        "  return theta, cost_history"
      ],
      "metadata": {
        "id": "X_qMp20VcZi5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "theta = [0., 0.]\n",
        "iterations = 1500;\n",
        "alpha = 0.01;"
      ],
      "metadata": {
        "id": "ymHDOAbjcg9A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "theta, cost_history = gradient_descent(X, y, theta, alpha, iterations)\n",
        "print('Final value of theta =', theta)\n",
        "print('cost_history =', cost_history)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AAJEHsy2clT2",
        "outputId": "a8220d7d-23dc-43f7-c51a-f64882c24869"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Final value of theta = [-3.63029144  1.16636235]\n",
            "cost_history = [6.73719046 5.93159357 5.90115471 ... 4.48343473 4.48341145 4.48338826]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Since X is list of list (feature matrix) lets take values of column of index 1 only\n",
        "plt.scatter(X[:,1], y, color='red', marker= '+', label= 'Training Data')\n",
        "plt.plot(X[:,1],X.dot(theta), color='green', label='Linear Regression')\n",
        "\n",
        "plt.rcParams[\"figure.figsize\"] = (10,6)\n",
        "plt.grid()\n",
        "plt.xlabel('Population of City in 10,000s')\n",
        "plt.ylabel('Profit in $10,000s')\n",
        "plt.title('Linear Regression Fit')\n",
        "plt.legend()"
      ],
      "metadata": {
        "id": "oB3-JFqSclaz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(range(1, iterations + 1),cost_history, color='blue')\n",
        "plt.rcParams[\"figure.figsize\"] = (10,6)\n",
        "plt.grid()\n",
        "plt.xlabel('Number of iterations')\n",
        "plt.ylabel('Cost (J)')\n",
        "plt.title('Convergence of gradient descent')"
      ],
      "metadata": {
        "id": "ylFRSf66cr2L"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}