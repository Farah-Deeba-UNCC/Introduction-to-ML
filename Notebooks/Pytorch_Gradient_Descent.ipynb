{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOByx6jvV0AUA+l+DCVPZdK",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Farah-Deeba-UNCC/Introduction-to-ML/blob/main/Notebooks/Pytorch_Gradient_Descent.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "HHimAnKwkt9a"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import torch"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "t_c = [0.5,  14.0, 15.0, 28.0, 11.0,  8.0,  3.0, -4.0,  6.0, 13.0, 21.0]\n",
        "t_u = [35.7, 55.9, 58.2, 81.9, 56.3, 48.9, 33.9, 21.8, 48.4, 60.4, 68.4]\n",
        "t_c = torch.tensor(t_c)\n",
        "t_u = torch.tensor(t_u)"
      ],
      "metadata": {
        "id": "8eTb6ZEAlCvM"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def model(t_u, w, b):\n",
        "    return w * t_u + b"
      ],
      "metadata": {
        "id": "V9G3H8urmnzO"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def loss_fn(t_p, t_c):\n",
        "    squared_diffs = (t_p - t_c)**2\n",
        "    return squared_diffs.mean()"
      ],
      "metadata": {
        "id": "YOwBR2iDmxwz"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "w = torch.ones(())\n",
        "b = torch.zeros(())\n",
        "\n",
        "t_p = model(t_u, w, b)\n",
        "t_p"
      ],
      "metadata": {
        "id": "6vKPafzGm7q8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "loss = loss_fn(t_p, t_c)\n",
        "loss"
      ],
      "metadata": {
        "id": "rKIJEkO5nA8w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# reuires_grad = True is telling PyTorch to track the entire family tree of tensors resulting from operating on all params involved in the model.\n",
        "params = torch.tensor([1.0,0.0],requires_grad=True)\n",
        "\n",
        "# Now we have to call the model and compute the loos and then call 'backward' on the loss tensor.\n",
        "loss = loss_fn(model(t_u, *params), t_c)\n",
        "params.grad\n"
      ],
      "metadata": {
        "id": "YBitrryBYOqg"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "loss.backward()\n",
        "params.grad"
      ],
      "metadata": {
        "id": "cGys6uRZbQFB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def training_loop(n_epochs, learning_rate, params, t_u,t_c):\n",
        "  for epoch in range(1,n_epochs+1):\n",
        "    if params.grad is not None:\n",
        "      params.grad.zero_()\n",
        "\n",
        "    t_p = model(t_u, *params)\n",
        "    loss = loss_fn(t_p,t_c)\n",
        "    loss.backward()\n",
        "\n",
        "    with torch.no_grad():\n",
        "      params -=learning_rate * params.grad\n",
        "\n",
        "    if epoch % 500 == 0:\n",
        "      print('Epoch %d, Loss %f' % (epoch, float(loss)))\n",
        "      print(params)\n",
        "      print(params.grad)\n",
        "  return params"
      ],
      "metadata": {
        "id": "pUrFQo2HgSXg"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "training_loop(\n",
        "    n_epochs = 5000,\n",
        "    learning_rate = 1e-4,\n",
        "    params = torch.tensor([1.0,0.0],requires_grad= True),\n",
        "    t_u = t_u,\n",
        "    t_c = t_c)\n",
        "print(params)"
      ],
      "metadata": {
        "id": "Wj3tJThzkDqL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# let's normalize the input\n",
        "t_un = 0.1*t_u"
      ],
      "metadata": {
        "id": "rkFv0tNvmN9e"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def training_loop(n_epochs, learning_rate, params, t_u,t_c):\n",
        "  for epoch in range(1,n_epochs+1):\n",
        "    if params.grad is not None:\n",
        "      params.grad.zero_()\n",
        "\n",
        "    t_p = model(t_u, *params)\n",
        "    loss = loss_fn(t_p,t_c)\n",
        "    loss.backward()\n",
        "\n",
        "    with torch.no_grad():\n",
        "      params -=learning_rate * params.grad\n",
        "\n",
        "    if epoch % 500 == 0:\n",
        "      print('Epoch %d, Loss %f' % (epoch, float(loss)))\n",
        "      print(params)\n",
        "      print(params.grad)\n",
        "  return params"
      ],
      "metadata": {
        "id": "bUMCnuMYmVpK"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "params = training_loop(\n",
        "    n_epochs = 5000,\n",
        "    learning_rate = 1e-2,\n",
        "    params = torch.tensor([1.0,0.0],requires_grad= True),\n",
        "    t_u = t_un,\n",
        "    t_c = t_c)\n",
        "print(params)"
      ],
      "metadata": {
        "id": "pajyDAZwmXNE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%matplotlib inline\n",
        "from matplotlib import pyplot as plt\n",
        "t_p = model(t_un, *params)\n",
        "fig = plt.figure(dpi=600)\n",
        "plt.xlabel(\"Temperature (°Fahrenheit)\")\n",
        "plt.ylabel(\"Temperature (°Celsius)\")\n",
        "plt.plot(t_u.numpy(), t_p.detach().numpy())\n",
        "plt.plot(t_u.numpy(), t_c.numpy(), 'o')"
      ],
      "metadata": {
        "id": "8KukuwAKnSUP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.optim as optim\n",
        "params = torch.tensor([1.0,0.0],requires_grad=True)\n",
        "learning_rate = 1e-5\n",
        "optimizer = optim.SGD([params],lr = learning_rate)"
      ],
      "metadata": {
        "id": "JGcsHMlQoxzS"
      },
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "t_p = model(t_u,*params)\n",
        "loss = loss_fn(t_p,t_c)\n",
        "loss.backward()\n",
        "optimizer.step()\n",
        "params\n"
      ],
      "metadata": {
        "id": "nzwpyo_XqX6n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def training_loop(n_epochs, optimizer, params, t_u,t_c):\n",
        "  for epoch in range(1,n_epochs+1):\n",
        "    t_p = model(t_u, *params)\n",
        "    loss = loss_fn(t_p,t_c)\n",
        "\n",
        "    optimizer.zero_grad()\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "\n",
        "\n",
        "    if epoch % 500 == 0:\n",
        "      print('Epoch %d, Loss %f' % (epoch, float(loss)))\n",
        "      print(params)\n",
        "      print(params.grad)\n",
        "  return params"
      ],
      "metadata": {
        "id": "vZ2NQai2sF4b"
      },
      "execution_count": 61,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "params = torch.tensor([1.0,0.0],requires_grad=True)\n",
        "learning_rate = 1e-2\n",
        "optimizer = optim.SGD([params],lr = learning_rate)\n",
        "training_loop(\n",
        "    n_epochs = 5000,\n",
        "    optimizer = optimizer,\n",
        "    params = params,\n",
        "    t_u = t_un,\n",
        "    t_c = t_c)\n",
        "print(params)\n",
        "\n",
        "params"
      ],
      "metadata": {
        "id": "q91PZCu_sbWo"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}